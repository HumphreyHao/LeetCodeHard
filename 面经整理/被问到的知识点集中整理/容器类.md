# HashMap

## Hashmap是怎么实现的?hashmap里面有一个resize方法,怎么实现的?hashmap如何扩容的?
HashMap实际上是一个一定长度的数组,数组中存放的是链表.
当向hashmap中添加元素时,也就是put方法,先算出哈希值,然后取模,然后将新加入的元素放在链表头上.
![](https://img-blog.csdn.net/20180620162511570?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmRlcmx1c3RMZWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

当从hashmap中获取元素的时候,也就是get方法,也是先计算hashcode,找到对应的数组位置,再对比key遍历链表.根据这个原理我们知道,如果每个index上的链表只有一个元素,效率是最高的.所以我们需要扩容机制.

扩容机制:
首先是初始容量大小:16,最大值是2^30.负载因子是0.75;HashMap的容量size乘以负载因子[默认0.75] = threshold, threshold即为开始扩容的临界值.
当hashmap中的元素个数超过数组大小的的0.75时,且新建的这个entry落在一个非空的桶上,就要把数组大小扩充为两倍,重新计算每个元素在数组中的位置.这个0.75的计算是大量实验统计出来的.如果取0.5就会造成资源浪费,如果取1,那么get/put碰撞几率增加.JavaDoc写0.75时链表长度服从参数为0.5的泊松分布
为什么容量必须是2的幂:可以看到这里是将哈希值h与桶数组的length-1（实际上也是map的容量-1）进行了一个与操作得出了对应的桶的位置，h & (length-1)。因为&比%这个操作符快了10倍左右.

1.8更新:
引入了红黑树,具体使用如下:
![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdjb252ZXJ0LmNzZG5pbWcuY24vYUhSMGNITTZMeTlwYldkamIyNTJaWEowTG1OelpHNXBiV2N1WTI0dllVaFNNR05FYjNaTU0xWjNZa2M1YUZwRE1YQmlWMFp1V2xoTmRXRnRiR2hpYms1dlpGTTFjR0o1T1RGalIzaDJXVmRTWm1GWE1XaGFNbFo2VEhwck1FNUVUVEpPVXpBd1RrUkZNMDFFV21wT1YwVTFUMWRWZDAxdFJYcE1ia0oxV25vNWNHSlhSbTVhVlRGMldqTkplVXd5UmpGa1J6aDBZak5LY0ZwWE5UQk1NMDR3WTIxc2QwcFVaRVJoVnpGb1dqSldWMkZYVmpOTmFUaDVURE5qZGsxVVNUQk5RUQ?x-oss-process=image/format,png)
主要就是在对应的节点处判断是否已经有数据,解决长链表查询缓慢的问题.
要注意1.8之后改成了尾插法,1.7是头插法.
因此数组元素和链表节点采用Node类实现.

因此加入了一些红黑树的相关参数:
```
// 1. 桶的树化阈值：即 链表转成红黑树的阈值，在存储数据时，当链表长度 > 该值时，则将链表转换成红黑树
   static final int TREEIFY_THRESHOLD = 8; 
   // 2. 桶的链表还原阈值：即 红黑树转为链表的阈值，当在扩容（resize（））时（此时HashMap的数据存储位置会重新计算），在重新计算存储位置后，当原有的红黑树内数量 < 6时，则将 红黑树转换成链表
   static final int UNTREEIFY_THRESHOLD = 6;
   // 3. 最小树形化容量阈值：即 当哈希表中的容量 > 该值时，才允许树形化链表 （即 将链表 转换成红黑树）
   // 否则，若桶内元素太多时，则直接扩容，而不是树形化
   // 为了避免进行扩容、树形化选择的冲突，这个值不能小于 4 * TREEIFY_THRESHOLD
   static final int MIN_TREEIFY_CAPACITY = 64;
```



hashcode的部分计算图:核心是高位参与低位运算,加大哈希码低位的随机性，使得分布更均匀，从而提高对应数组存储下标位置的随机性 & 均匀性，最终减少Hash冲突
![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdjb252ZXJ0LmNzZG5pbWcuY24vYUhSMGNITTZMeTlwYldkamIyNTJaWEowTG1OelpHNXBiV2N1WTI0dllVaFNNR05FYjNaTU0xWjNZa2M1YUZwRE1YQmlWMFp1V2xoTmRXRnRiR2hpYms1dlpGTTFjR0o1T1RGalIzaDJXVmRTWm1GWE1XaGFNbFo2VEhwck1FNUVUVEpPVXpBd1dsZFdhazE2U1RSYVZHaHJXa1JPYTA0eVZUTk1ia0oxV25vNWNHSlhSbTVhVlRGMldqTkplVXd5UmpGa1J6aDBZak5LY0ZwWE5UQk1NMDR3WTIxc2QwcFVaRVJoVnpGb1dqSldWMkZYVmpOTmFUaDVURE5qZGsxVVNUQk5RUQ?x-oss-process=image/format,png)

插入操作也进行了优化,如下图:
![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdjb252ZXJ0LmNzZG5pbWcuY24vYUhSMGNITTZMeTlwYldkamIyNTJaWEowTG1OelpHNXBiV2N1WTI0dllVaFNNR05FYjNaTU0xWjNZa2M1YUZwRE1YQmlWMFp1V2xoTmRXRnRiR2hpYms1dlpGTTFjR0o1T1RGalIzaDJXVmRTWm1GWE1XaGFNbFo2VEhwck1FNUVUVEpPVXpBeFRUSkpkMDU2VlhsTmJVbDZUa1JPYkZsdFZUVk1ia0oxV25vNWNHSlhSbTVhVlRGMldqTkplVXd5UmpGa1J6aDBZak5LY0ZwWE5UQk1NMDR3WTIxc2QwcFVaRVJoVnpGb1dqSldWMkZYVmpOTmFUaDVURE5qZGsxVVNUQk5RUQ?x-oss-process=image/format,png)
核心是先判断是否要树化,再判断是否扩容;

扩容部分也进行了优化:
![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdjb252ZXJ0LmNzZG5pbWcuY24vYUhSMGNITTZMeTlwYldkamIyNTJaWEowTG1OelpHNXBiV2N1WTI0dllVaFNNR05FYjNaTU0xWjNZa2M1YUZwRE1YQmlWMFp1V2xoTmRXRnRiR2hpYms1dlpGTTFjR0o1T1RGalIzaDJXVmRTWm1GWE1XaGFNbFo2VEhwck1FNUVUVEpPVXpGb1RYcEdiRTVVUm1sTmFsSnRUVlJOTVZwRVpHcE1ia0oxV25vNWNHSlhSbTVhVlRGMldqTkplVXd5UmpGa1J6aDBZak5LY0ZwWE5UQk1NMDR3WTIxc2QwcFVaRVJoVnpGb1dqSldWMkZYVmpOTmFUaDVURE5qZGsxVVNUQk5RUQ?x-oss-process=image/format,png)
主要区别是:
1,1.8的扩容包含了待插入的数据
2,1.8的新位置直接是原位置,或者原位置+旧容量,避免了再次计算.
3,使用尾插法

HashMap 线程不安全的其中一个重要原因：多线程下容易出现resize（）死循环

# 优先队列
添加复杂度为logN,取出复杂度为logN,peek为O1,默认是升序.