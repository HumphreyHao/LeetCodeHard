# HashMap

## Hashmap是怎么实现的?hashmap里面有一个resize方法,怎么实现的?hashmap如何扩容的?
HashMap实际上是一个一定长度的数组,数组中存放的是链表.
当向hashmap中添加元素时,也就是put方法,先算出哈希值,然后取模,然后将新加入的元素放在链表头上.
![](https://img-blog.csdn.net/20180620162511570?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dhbmRlcmx1c3RMZWU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

当从hashmap中获取元素的时候,也就是get方法,也是先计算hashcode,找到对应的数组位置,再对比key遍历链表.根据这个原理我们知道,如果每个index上的链表只有一个元素,效率是最高的.所以我们需要扩容机制.

扩容机制:
首先是初始容量大小:16,最大值是2^30.负载因子是0.75;HashMap的容量size乘以负载因子[默认0.75] = threshold, threshold即为开始扩容的临界值.
当hashmap中的元素个数超过数组大小的的0.75时,且新建的这个entry落在一个非空的桶上,就要把数组大小扩充为两倍,重新计算每个元素在数组中的位置.这个0.75的计算是大量实验统计出来的.如果取0.5就会造成资源浪费,如果取1,那么get/put碰撞几率增加.JavaDoc写0.75时链表长度服从参数为0.5的泊松分布
为什么容量必须是2的幂:可以看到这里是将哈希值h与桶数组的length-1（实际上也是map的容量-1）进行了一个与操作得出了对应的桶的位置，h & (length-1)。因为&比%这个操作符快了10倍左右.

1.8更新:
引入了红黑树,具体使用如下:
![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdjb252ZXJ0LmNzZG5pbWcuY24vYUhSMGNITTZMeTlwYldkamIyNTJaWEowTG1OelpHNXBiV2N1WTI0dllVaFNNR05FYjNaTU0xWjNZa2M1YUZwRE1YQmlWMFp1V2xoTmRXRnRiR2hpYms1dlpGTTFjR0o1T1RGalIzaDJXVmRTWm1GWE1XaGFNbFo2VEhwck1FNUVUVEpPVXpBd1RrUkZNMDFFV21wT1YwVTFUMWRWZDAxdFJYcE1ia0oxV25vNWNHSlhSbTVhVlRGMldqTkplVXd5UmpGa1J6aDBZak5LY0ZwWE5UQk1NMDR3WTIxc2QwcFVaRVJoVnpGb1dqSldWMkZYVmpOTmFUaDVURE5qZGsxVVNUQk5RUQ?x-oss-process=image/format,png)
主要就是在对应的节点处判断是否已经有数据,解决长链表查询缓慢的问题.
要注意1.8之后改成了尾插法,1.7是头插法.
因此数组元素和链表节点采用Node类实现.

因此加入了一些红黑树的相关参数:
```
// 1. 桶的树化阈值：即 链表转成红黑树的阈值，在存储数据时，当链表长度 > 该值时，则将链表转换成红黑树
   static final int TREEIFY_THRESHOLD = 8; 
   // 2. 桶的链表还原阈值：即 红黑树转为链表的阈值，当在扩容（resize（））时（此时HashMap的数据存储位置会重新计算），在重新计算存储位置后，当原有的红黑树内数量 < 6时，则将 红黑树转换成链表
   static final int UNTREEIFY_THRESHOLD = 6;
   // 3. 最小树形化容量阈值：即 当哈希表中的容量 > 该值时，才允许树形化链表 （即 将链表 转换成红黑树）
   // 否则，若桶内元素太多时，则直接扩容，而不是树形化
   // 为了避免进行扩容、树形化选择的冲突，这个值不能小于 4 * TREEIFY_THRESHOLD
   static final int MIN_TREEIFY_CAPACITY = 64;
```



hashcode的部分计算图:核心是高位参与低位运算,加大哈希码低位的随机性，使得分布更均匀，从而提高对应数组存储下标位置的随机性 & 均匀性，最终减少Hash冲突
![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdjb252ZXJ0LmNzZG5pbWcuY24vYUhSMGNITTZMeTlwYldkamIyNTJaWEowTG1OelpHNXBiV2N1WTI0dllVaFNNR05FYjNaTU0xWjNZa2M1YUZwRE1YQmlWMFp1V2xoTmRXRnRiR2hpYms1dlpGTTFjR0o1T1RGalIzaDJXVmRTWm1GWE1XaGFNbFo2VEhwck1FNUVUVEpPVXpBd1dsZFdhazE2U1RSYVZHaHJXa1JPYTA0eVZUTk1ia0oxV25vNWNHSlhSbTVhVlRGMldqTkplVXd5UmpGa1J6aDBZak5LY0ZwWE5UQk1NMDR3WTIxc2QwcFVaRVJoVnpGb1dqSldWMkZYVmpOTmFUaDVURE5qZGsxVVNUQk5RUQ?x-oss-process=image/format,png)

插入操作也进行了优化,如下图:
![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdjb252ZXJ0LmNzZG5pbWcuY24vYUhSMGNITTZMeTlwYldkamIyNTJaWEowTG1OelpHNXBiV2N1WTI0dllVaFNNR05FYjNaTU0xWjNZa2M1YUZwRE1YQmlWMFp1V2xoTmRXRnRiR2hpYms1dlpGTTFjR0o1T1RGalIzaDJXVmRTWm1GWE1XaGFNbFo2VEhwck1FNUVUVEpPVXpBeFRUSkpkMDU2VlhsTmJVbDZUa1JPYkZsdFZUVk1ia0oxV25vNWNHSlhSbTVhVlRGMldqTkplVXd5UmpGa1J6aDBZak5LY0ZwWE5UQk1NMDR3WTIxc2QwcFVaRVJoVnpGb1dqSldWMkZYVmpOTmFUaDVURE5qZGsxVVNUQk5RUQ?x-oss-process=image/format,png)
核心是先判断是否要树化,再判断是否扩容;

扩容部分也进行了优化:
![](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWdjb252ZXJ0LmNzZG5pbWcuY24vYUhSMGNITTZMeTlwYldkamIyNTJaWEowTG1OelpHNXBiV2N1WTI0dllVaFNNR05FYjNaTU0xWjNZa2M1YUZwRE1YQmlWMFp1V2xoTmRXRnRiR2hpYms1dlpGTTFjR0o1T1RGalIzaDJXVmRTWm1GWE1XaGFNbFo2VEhwck1FNUVUVEpPVXpGb1RYcEdiRTVVUm1sTmFsSnRUVlJOTVZwRVpHcE1ia0oxV25vNWNHSlhSbTVhVlRGMldqTkplVXd5UmpGa1J6aDBZak5LY0ZwWE5UQk1NMDR3WTIxc2QwcFVaRVJoVnpGb1dqSldWMkZYVmpOTmFUaDVURE5qZGsxVVNUQk5RUQ?x-oss-process=image/format,png)
主要区别是:
1,1.8的扩容包含了待插入的数据
2,1.8的新位置直接是原位置,或者原位置+旧容量,避免了再次计算.
3,使用尾插法

HashMap 线程不安全的其中一个重要原因：多线程下容易出现resize（）死循环

## 为什么使用红黑树而不是AVL树
因为红黑树不需要存储平衡因子,节约内存,而且删除和插入更加的快.AVL查找更快.
而且AVL树的旋转更加难以控制和调试


# 优先队列
添加复杂度为logN,取出复杂度为logN,peek为O1,默认是升序.


## 讲一下concurrenthashmap的实现原理
这里直接总结一下常用的java并发数据结构
*CountDownLatch* - 同步工具类

这个类可以让一个线程等待其他线程完成各自的工作之后再执行,很少使用.

*BlockingQueue* - 阻塞队列
常用实现:
ArrayBlockingQueue

LinkedBlockingQueue

于链表的阻塞队列，同ArrayListBlockingQueue类似，其内部也维持着一个数据缓冲队列（该队列由一个链表构成），当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列

PriorityBlockingQueue

基于优先级的阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），但需要注意的是PriorityBlockingQueue并不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。

*ConcurrentLinkedQueue*-非阻塞队列
这是非阻塞的,队列中元素按照FIFO原则排序,采用CAS操作保证元素一致性.
他的自带操作是原子的,但是如果是自己写的非原子操作,还是需要自己加锁

**ConcurrentHashMap** 非常非常重要的数据结构
因为HashMap线程不安全,Hashtable所有的重要方法都加了synchronized 关键字修饰,所以线程安全;

ConcurrentHashMap引入了一个分段锁的概念,把一个大的Map拆分成了N个小的HashTable,默认是16个;所以相当于是16个锁,提高了效率;

*ThreadLocal<T>* 创建线程副本
通过为每个线程实现ThreadLocalMap来实现每个线程有独立变量