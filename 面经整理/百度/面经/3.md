# 质量效能研发部java实习
    https://www.nowcoder.com/discuss/445528?type=2&order=0&pos=16&page=1&channel=-2&source_id=discuss_tag

## 讲一下concurrenthashmap的实现原理
这里直接总结一下常用的java并发数据结构
*CountDownLatch* - 同步工具类

这个类可以让一个线程等待其他线程完成各自的工作之后再执行,很少使用.

*BlockingQueue* - 阻塞队列
常用实现:
ArrayBlockingQueue

LinkedBlockingQueue

于链表的阻塞队列，同ArrayListBlockingQueue类似，其内部也维持着一个数据缓冲队列（该队列由一个链表构成），当生产者往队列中放入一个数据时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue可以通过构造函数指定该值），才会阻塞生产者队列

PriorityBlockingQueue

基于优先级的阻塞队列（优先级的判断通过构造函数传入的Compator对象来决定），但需要注意的是PriorityBlockingQueue并不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞数据的消费者。因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。

*ConcurrentLinkedQueue*-非阻塞队列
这是非阻塞的,队列中元素按照FIFO原则排序,采用CAS操作保证元素一致性.
他的自带操作是原子的,但是如果是自己写的非原子操作,还是需要自己加锁

**ConcurrentHashMap** 非常非常重要的数据结构
因为HashMap线程不安全,Hashtable所有的重要方法都加了synchronized 关键字修饰,所以线程安全;

ConcurrentHashMap引入了一个分段锁的概念,把一个大的Map拆分成了N个小的HashTable,默认是16个;所以相当于是16个锁,提高了效率;

*ThreadLocal<T>* 创建线程副本
通过为每个线程实现ThreadLocalMap来实现每个线程有独立变量




## 讲一下RocketMQ/Kafka
使用原因：异步，解藕，削峰。
RMQ是根据Kafak的架构原型设计出来的,有很多地方相似.但是RMQ的吞吐量是10wTPS,Kafka是百万.K使用zookeeper作为nameserver，nameserver就是帮助producer和consumer路由到Broker

K是每个Partition一个文件,R是所有topic都存在一个文件.

消息写入:
1） 顺序写入
2） 利用OS提供的pageCache来实现mmap（内存映射文件），java中是通过NOI提供的MappedByteBuffer类具体实现的

消息读取:
两者都采用了一个技术叫做零拷贝，这样就不用先将磁盘内容从内核空间（磁盘的）拷贝到用户空间，再从用户空间拷贝到内核空间（socket的），而是直接从内核转到内核，java里面是通过NIO提供的FileChannel实现。

零拷贝:磁盘数据通过 DMA 拷贝到内核态 Buffer 后，直接通过 DMA 拷贝到 NIC Buffer(socket buffer)，无需 CPU 拷贝,这一步叫send file
正常拷贝需要拷贝4次:
1、第一次：将磁盘文件，读取到操作系统内核缓冲区；
2、第二次：将内核缓冲区的数据，copy到application应用程序的buffer；
3、第三步：将application应用程序buffer中的数据，copy到socket网络发送缓冲区(属于操作系统内核的缓冲区)；
4、第四次：将socket buffer的数据，copy到网卡，由网卡进行网络传输。
![](https://pic2.zhimg.com/80/v2-07f829c7a070c3444b1d8c99d4afd1bb_1440w.jpg)

但是零拷贝就是把中间过程省略,变成共享内存的方式,减少拷贝次数.具体是使用
mmap文件映射机制,Memory Mapped Files，简单描述其作用就是：将磁盘文件映射到内存, 用户通过修改内存就能修改磁盘文件。
在进程 的非堆内存开辟一块内存空间，和OS内核空间的一块内存进行映射，
kafka数据写入、是写入这块内存空间，但实际这块内存和OS内核内存有映射，也就是相当于写在内核内存空间了，且这块内核空间、内核直接能够访问到，直接落入磁盘。这里，我们需要清楚的是：内核缓冲区的数据，flush就能完成落盘。


Kafka为什么快:
1、partition顺序读写，充分利用磁盘特性，这是基础；
2、Producer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入；
3、Customer从broker读取数据，采用sendfile，将磁盘文件读到OS内核缓冲区后，直接转到socket buffer进行网络发送。
4、kafka采用异步发送的机制，当发送一条消息时，消息并没有发送到broker而是缓存起来，然后直接向业务返回成功，当缓存的消息达到一定数量时再批量发送。此时减少了网络io，从而提高了消息发送的性能，但是如果消息发送者宕机，会导致消息丢失，业务出错，所以理论上kafka利用此机制提高了io性能却降低了可靠性。

Kafka的消息存储：
https://www.jianshu.com/p/7da49ff4f565

如何保证消息的顺序性：
https://www.jianshu.com/p/8a5630e2c317

Kafka的手段是：写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。


## 手写一下快排的代码
快速排序是挖坑填数+分治来实现的
快速排序的基本思想:
1．先从数列中取出一个数作为基准数。

2．分区过程，将比这个数大的数全放到它的右边，小于或等于它的数全放到它的左边。

3．再对左右区间重复第二步，直到各区间只有一个数。

挖坑法实现:
```
public static void pothlingSort(int[] arrays , int low , int high){
    if(low < high){
        //求每次分治的分割线
		int divideIndex = getDivideIndex(arrays,low,high);
        //再递归分别对分割的俩个子数组进行递归排序
		pothlingSort(arrays,low,divideIndex -1);
		pothlingSort(arrays,divideIndex + 1, high);
    }
}

private static int getDivideIndex(int[] arrays, int low, int high) {
    // 将数组最左端arrays[0]作为默认的基准值,将最左端的值放至基准值的坑内。
    // 此时arrays[0]没有值了，需要从最右端找到一个比基准值小的数填至[0]这个坑。
    // 再从左到右找到一个比基准值大的数填到刚才的坑。循环进行直到low=high
    // 将基准值填至刚才的low位置。再进行分治

    int baseValue = arrays[low];
    arrays[low] =0 ; //挖个坑

    while(low <high){
        //从右往左,找第一个比坑数小的数字
        while(low < high && arrays[high] >= baseValue){
				high--;
			}
        
        arrays[low] = arrays[high] ;
		arrays[high] = 0 ;

        //从左往右,找第一个比坑大的数字
        while(low < high && arrays[low] <= baseValue){
				low++;
			}
			arrays[high] = arrays[low] ;
			arrays[low] = 0 ;
    }

    if(low == high){
			arrays[low] = baseValue;
		}
		
		return low;
    //最后坑填完了,返回坑,或者不返回
}
```